{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only the 2018 file is different, there are some missing columns, such as COD_INST and NOM_INST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadinfo(category):\n",
    "    \n",
    "    categoryDatasets = []\n",
    "    for year in range(2008,2019):\n",
    "        filePath = \"../Data/newData/{0}/{0}{1}.txt\".format(category,year)\n",
    "        df = pd.read_csv(filePath,sep='\\t',encoding='ISO-8859-1)\n",
    "        df.columns = df.columns.str.upper()\n",
    "        df[\"FILE_YEAR\"] = year\n",
    "        df[\"ORIGINAL_FILE\"] = filePath        \n",
    "        categoryDatasets.append(df)\n",
    "    return categoryDatasets\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[e.shape[0] for e in loadinfo(\"nac\")] # To inspect characteristics on info loaded of a specific category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def mergeDfs(listToMerge):\n",
    "    df = (pd.concat(listToMerge)  \n",
    "          .replace(' ',np.nan)    #replace missing values\n",
    "          .reset_index(drop=True)) #reset index and drop old indices\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfList = [mergeDfs(loadinfo(category)) for category in [\"nac\",\"fetal\",\"defun\"]]\n",
    "unifiedDf = mergeDfs(dfList)\n",
    "nacDf, fetalDf, nofetalDf = dfList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nofetalDf.head().columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "['COD_DPTO', 'COD_MUNIC', 'AREANAC', 'SIT_PARTO', 'OTRO_SIT', 'NOM_INST',\n",
    "       'COD_INST', 'SEXO', 'PESO_NAC', 'TALLA_NAC', 'ANO', 'MES', 'ATEN_PAR',\n",
    "       'OTRPARATX', 'T_GES', 'NUMCONSUL', 'TIPO_PARTO', 'MUL_PARTO', 'APGAR1',\n",
    "       'APGAR2', 'IDHEMOCLAS', 'IDFACTORRH', 'IDPUEBLOIN', 'EDAD_MADRE',\n",
    "       'EST_CIVM', 'NIV_EDUM', 'ULTCURMAD', 'CODPRES', 'CODPTORE', 'CODMUNRE',\n",
    "       'AREA_RES', 'N_HIJOSV', 'FECHA_NACM', 'N_EMB', 'SEG_SOCIAL',\n",
    "       'IDCLASADMI', 'NOMCLASAD', 'EDAD_PADRE', 'NIV_EDUP', 'ULTCURPAD',\n",
    "       'PROFESION', 'FILE_YEAR', 'ORIGINAL_FILE', 'IDPERTET']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unifiedDf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nacDf.to_csv(\"../Data/CleanData/Unified/nacUnified.csv\")\n",
    "fetalDf.to_csv(\"../Data/CleanData/Unified/fetalUnified.csv\")\n",
    "nofetalDf.to_csv(\"../Data/CleanData/Unified/nofetalUnified.csv\")\n",
    "unifiedDf.to_csv(\"../Data/CleanData/Unified/allUnified.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import logging\n",
    "# import boto3\n",
    "# from botocore.exceptions import ClientError\n",
    "# import os\n",
    "# from io import StringIO\n",
    "\n",
    "# aws_access_key_id=\"AKIAVIHLFDBFCCYTFQVJ\"\n",
    "# aws_secret_access_key=\"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\"\n",
    "# bucket = \"ds4a.finalproject\"\n",
    "\n",
    "# def upload_data(data,bucket,key,aws_access_key_id,aws_secret_access_key):\n",
    "#     '''\n",
    "#         Upload data to storage S3, aws_acces_key_id and aws_secret_access_key are provided by AWS.\n",
    "#         This function is only if you require save the information in SW. \n",
    "#     '''\n",
    "\n",
    "#     client = boto3.client('s3',\n",
    "#                           aws_access_key_id=aws_access_key_id,\n",
    "#                           aws_secret_access_key=aws_secret_access_key)\n",
    "#     csv_buffer = StringIO()\n",
    "#     data.to_csv(csv_buffer, index=False)\n",
    "#     csv_buffer.seek(0)\n",
    "#     obj = client.put_object(Bucket=bucket, \n",
    "#                             Key=key, \n",
    "#                             Body=csv_buffer.getvalue(), \n",
    "#                             ACL='public-read')\n",
    "\n",
    "#     return obj\n",
    "\n",
    "# filename = \"nacUnified.csv\"\n",
    "\n",
    "# upload_data(nacDf,bucket,filename,aws_access_key_id,aws_secret_access_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.read_csv('https://s3.us-east-2.amazonaws.com/ds4a.finalproject/nacUnified.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
